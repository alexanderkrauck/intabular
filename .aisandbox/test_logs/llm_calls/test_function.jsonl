{"timestamp": "2025-06-01T12:03:27.657611", "caller": "test_function", "model": "gpt-4o-mini", "temperature": 0.1, "prompt": "This is a test prompt for logging demonstration", "full_request": {"model": "gpt-4o-mini", "messages": [{"role": "user", "content": "This is a test prompt for logging demonstration"}], "temperature": 0.1, "max_tokens": 100}, "response": {"id": "test-123", "model": "gpt-4o-mini", "choices": [{"message": {"content": "Test response"}}]}}
